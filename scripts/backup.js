#!/usr/bin/env node

const { Client } = require("pg");
const fs = require("fs");
const path = require("path");
const zlib = require("zlib");

/**
 * Professional PostgreSQL Backup Script
 * Supports all database objects: tables, views, sequences, functions, triggers, enums, etc.
 * Serverless-compatible (no pg_dump required)
 */

async function createBackup(connectionString, backupName, options = {}) {
  const {
    compress = false,
    schemasOnly = null,
    dataOnly = false,
    schemaOnly = false,
  } = options;

  const client = new Client({
    connectionString: connectionString,
    ssl: {
      rejectUnauthorized: false,
    },
  });

  try {
    console.log("üîå Connecting to database...");
    await client.connect();
    console.log("‚úÖ Connected successfully!");

    // Get database info
    const dbInfo = await client.query("SELECT current_database(), version()");
    const databaseName = dbInfo.rows[0].current_database;
    const postgresVersion = dbInfo.rows[0].version;

    const backupDir = path.join(process.cwd(), "backups");
    if (!fs.existsSync(backupDir)) {
      fs.mkdirSync(backupDir, { recursive: true });
    }

    const timestamp = new Date().toISOString().replace(/[:.]/g, "-");
    const filename = `${backupName}_${timestamp}.sql${compress ? ".gz" : ""}`;
    const filepath = path.join(backupDir, filename);
    const metadataPath = path.join(
      backupDir,
      `${backupName}_${timestamp}.json`,
    );

    let writeStream;
    let sqlContent = "";

    const write = (content) => {
      sqlContent += content;
    };

    // Write header
    write(`-- PostgreSQL Database Backup\n`);
    write(`-- Backup Name: ${backupName}\n`);
    write(`-- Database: ${databaseName}\n`);
    write(`-- PostgreSQL Version: ${postgresVersion}\n`);
    write(`-- Created: ${new Date().toISOString()}\n`);
    write(`-- Generated by: Professional PostgreSQL Backup Tool\n\n`);
    write(`SET statement_timeout = 0;\n`);
    write(`SET lock_timeout = 0;\n`);
    write(`SET client_encoding = 'UTF8';\n`);
    write(`SET standard_conforming_strings = on;\n`);
    write(`SET check_function_bodies = false;\n`);
    write(`SET xmloption = content;\n`);
    write(`SET client_min_messages = warning;\n\n`);

    // Get all schemas (excluding system schemas)
    console.log("üìã Fetching schemas...");
    const schemasResult = await client.query(
      `
      SELECT schema_name 
      FROM information_schema.schemata 
      WHERE schema_name NOT IN ('pg_catalog', 'information_schema', 'pg_toast', 'pg_temp_1', 'pg_toast_temp_1')
      ${schemasOnly ? `AND schema_name = ANY($1)` : ""}
      ORDER BY schema_name;
    `,
      schemasOnly ? [schemasOnly] : [],
    );

    const schemas = schemasResult.rows.map((r) => r.schema_name);
    const objectCounts = {
      tables: 0,
      views: 0,
      sequences: 0,
      functions: 0,
      triggers: 0,
      enums: 0,
      extensions: 0,
    };

    // Backup extensions
    if (!dataOnly) {
      console.log("üîå Backing up extensions...");
      const extensionsResult = await client.query(`
        SELECT extname, extversion
        FROM pg_extension
        WHERE extname NOT IN ('plpgsql')
        ORDER BY extname;
      `);

      if (extensionsResult.rows.length > 0) {
        write(`\n-- Extensions\n`);
        for (const ext of extensionsResult.rows) {
          write(
            `CREATE EXTENSION IF NOT EXISTS "${ext.extname}" WITH SCHEMA public VERSION '${ext.extversion}';\n`,
          );
          objectCounts.extensions++;
        }
        write(`\n`);
      }
    }

    // Backup enums and custom types
    if (!dataOnly) {
      console.log("üè∑Ô∏è  Backing up enums and custom types...");
      for (const schema of schemas) {
        const enumsResult = await client.query(
          `
          SELECT t.typname, e.enumlabel
          FROM pg_type t
          JOIN pg_enum e ON t.oid = e.enumtypid
          JOIN pg_namespace n ON t.typnamespace = n.oid
          WHERE n.nspname = $1
          ORDER BY t.typname, e.enumsortorder;
        `,
          [schema],
        );

        if (enumsResult.rows.length > 0) {
          const enumsByType = {};
          for (const row of enumsResult.rows) {
            if (!enumsByType[row.typname]) {
              enumsByType[row.typname] = [];
            }
            enumsByType[row.typname].push(row.enumlabel);
          }

          write(`\n-- Enums in schema: ${schema}\n`);
          for (const [typname, labels] of Object.entries(enumsByType)) {
            write(`DROP TYPE IF EXISTS ${schema}.${typname} CASCADE;\n`);
            write(`CREATE TYPE ${schema}.${typname} AS ENUM (\n`);
            write(
              labels.map((l) => `  '${l.replace(/'/g, "''")}'`).join(",\n"),
            );
            write(`\n);\n\n`);
            objectCounts.enums++;
          }
        }
      }
    }

    for (const schema of schemas) {
      write(`\n-- ============================================\n`);
      write(`-- Schema: ${schema}\n`);
      write(`-- ============================================\n\n`);
      write(`CREATE SCHEMA IF NOT EXISTS ${schema};\n\n`);

      // Backup sequences
      if (!dataOnly) {
        console.log(`üî¢ Backing up sequences from schema: ${schema}...`);
        const sequencesResult = await client.query(
          `
          SELECT sequence_name
          FROM information_schema.sequences
          WHERE sequence_schema = $1
          ORDER BY sequence_name;
        `,
          [schema],
        );

        for (const seqRow of sequencesResult.rows) {
          const seqName = seqRow.sequence_name;
          const fullSeqName = `${schema}.${seqName}`;

          const seqDetails = await client.query(`
            SELECT * FROM ${fullSeqName}
          `);

          if (seqDetails.rows.length > 0) {
            const seq = seqDetails.rows[0];
            write(`\n-- Sequence: ${fullSeqName}\n`);
            write(`DROP SEQUENCE IF EXISTS ${fullSeqName} CASCADE;\n`);
            write(`CREATE SEQUENCE ${fullSeqName}\n`);
            write(`  START WITH ${seq.last_value}\n`);
            write(`  INCREMENT BY ${seq.increment_by || 1}\n`);
            write(`  MINVALUE ${seq.min_value}\n`);
            write(`  MAXVALUE ${seq.max_value}\n`);
            write(`  CACHE ${seq.cache_size || 1};\n\n`);
            objectCounts.sequences++;
          }
        }
      }

      // Backup views
      if (!dataOnly) {
        console.log(`üëÅÔ∏è  Backing up views from schema: ${schema}...`);
        const viewsResult = await client.query(
          `
          SELECT table_name, view_definition
          FROM information_schema.views
          WHERE table_schema = $1
          ORDER BY table_name;
        `,
          [schema],
        );

        for (const viewRow of viewsResult.rows) {
          const viewName = viewRow.table_name;
          const fullViewName = `${schema}.${viewName}`;
          write(`\n-- View: ${fullViewName}\n`);
          write(`DROP VIEW IF EXISTS ${fullViewName} CASCADE;\n`);
          write(
            `CREATE VIEW ${fullViewName} AS\n${viewRow.view_definition}\n\n`,
          );
          objectCounts.views++;
        }
      }

      // Get all tables in this schema
      console.log(`üìä Fetching tables from schema: ${schema}...`);
      const tablesResult = await client.query(
        `
        SELECT table_name 
        FROM information_schema.tables 
        WHERE table_schema = $1 AND table_type = 'BASE TABLE'
        ORDER BY table_name;
      `,
        [schema],
      );

      for (const tableRow of tablesResult.rows) {
        const table = tableRow.table_name;
        const fullTableName = `${schema}.${table}`;

        console.log(`  üì¶ Backing up table: ${fullTableName}...`);

        if (!dataOnly) {
          // Get table structure
          const columnsResult = await client.query(
            `
            SELECT 
              column_name,
              data_type,
              udt_name,
              character_maximum_length,
              numeric_precision,
              numeric_scale,
              column_default,
              is_nullable,
              is_identity,
              identity_generation
            FROM information_schema.columns
            WHERE table_schema = $1 AND table_name = $2
            ORDER BY ordinal_position;
          `,
            [schema, table],
          );

          write(`\n-- Table: ${fullTableName}\n`);
          write(`DROP TABLE IF EXISTS ${fullTableName} CASCADE;\n`);
          write(`CREATE TABLE ${fullTableName} (\n`);

          const columnDefs = columnsResult.rows.map((col, idx) => {
            let def = `  "${col.column_name}" `;

            // Handle data type
            if (col.data_type === "ARRAY") {
              def += `${col.udt_name.replace("_", "")}[]`;
            } else if (col.data_type === "USER-DEFINED") {
              def += col.udt_name;
            } else {
              def += col.data_type.toUpperCase();
              if (col.character_maximum_length) {
                def += `(${col.character_maximum_length})`;
              } else if (col.numeric_precision) {
                def += `(${col.numeric_precision}${col.numeric_scale ? "," + col.numeric_scale : ""})`;
              }
            }

            // Handle identity columns
            if (col.is_identity === "YES") {
              def += ` GENERATED ${col.identity_generation} AS IDENTITY`;
            } else if (col.column_default) {
              def += ` DEFAULT ${col.column_default}`;
            }

            if (col.is_nullable === "NO") {
              def += " NOT NULL";
            }

            return def;
          });

          write(columnDefs.join(",\n"));
          write("\n);\n\n");

          // Get primary keys
          const pkResult = await client.query(
            `
            SELECT a.attname
            FROM pg_index i
            JOIN pg_attribute a ON a.attrelid = i.indrelid AND a.attnum = ANY(i.indkey)
            WHERE i.indrelid = $1::regclass AND i.indisprimary;
          `,
            [fullTableName],
          );

          if (pkResult.rows.length > 0) {
            const pkColumns = pkResult.rows
              .map((r) => `"${r.attname}"`)
              .join(", ");
            write(
              `ALTER TABLE ${fullTableName} ADD PRIMARY KEY (${pkColumns});\n\n`,
            );
          }

          // Get unique constraints
          const uniqueResult = await client.query(
            `
            SELECT conname, pg_get_constraintdef(oid) as condef
            FROM pg_constraint
            WHERE conrelid = $1::regclass AND contype = 'u';
          `,
            [fullTableName],
          );

          for (const uc of uniqueResult.rows) {
            write(
              `ALTER TABLE ${fullTableName} ADD CONSTRAINT "${uc.conname}" ${uc.condef};\n`,
            );
          }

          // Get check constraints
          const checkResult = await client.query(
            `
            SELECT conname, pg_get_constraintdef(oid) as condef
            FROM pg_constraint
            WHERE conrelid = $1::regclass AND contype = 'c';
          `,
            [fullTableName],
          );

          for (const cc of checkResult.rows) {
            write(
              `ALTER TABLE ${fullTableName} ADD CONSTRAINT "${cc.conname}" ${cc.condef};\n`,
            );
          }

          if (uniqueResult.rows.length > 0 || checkResult.rows.length > 0) {
            write("\n");
          }

          objectCounts.tables++;
        }

        // Get data
        if (!schemaOnly) {
          const countResult = await client.query(
            `SELECT COUNT(*) as count FROM ${fullTableName}`,
          );
          const rowCount = parseInt(countResult.rows[0].count);

          if (rowCount > 0) {
            write(`-- Data for ${fullTableName} (${rowCount} rows)\n`);

            const dataResult = await client.query(
              `SELECT * FROM ${fullTableName}`,
            );
            const columns = dataResult.fields.map((f) => f.name);

            for (const row of dataResult.rows) {
              const values = columns.map((col) => {
                const val = row[col];
                if (val === null) return "NULL";
                if (typeof val === "boolean") return val ? "true" : "false";
                if (typeof val === "number") return val.toString();
                if (val instanceof Date) return `'${val.toISOString()}'`;
                if (typeof val === "object") {
                  return `'${JSON.stringify(val).replace(/'/g, "''")}'`;
                }
                if (typeof val === "string") {
                  return `'${val.replace(/'/g, "''").replace(/\\/g, "\\\\")}'`;
                }
                return `'${String(val).replace(/'/g, "''")}'`;
              });

              write(
                `INSERT INTO ${fullTableName} (${columns.map((c) => `"${c}"`).join(", ")}) VALUES (${values.join(", ")});\n`,
              );
            }
            write("\n");
          }
        }
      }

      // Backup indexes (excluding primary key indexes)
      if (!dataOnly) {
        console.log(`üîç Backing up indexes from schema: ${schema}...`);
        const indexesResult = await client.query(
          `
          SELECT indexname, indexdef
          FROM pg_indexes
          WHERE schemaname = $1
          AND indexname NOT LIKE '%_pkey'
          ORDER BY tablename, indexname;
        `,
          [schema],
        );

        if (indexesResult.rows.length > 0) {
          write(`\n-- Indexes for schema: ${schema}\n`);
          for (const idx of indexesResult.rows) {
            write(`${idx.indexdef};\n`);
          }
          write("\n");
        }
      }

      // Backup foreign keys
      if (!dataOnly) {
        console.log(`üîó Backing up foreign keys from schema: ${schema}...`);
        const fkResult = await client.query(
          `
          SELECT
            tc.table_name,
            tc.constraint_name,
            pg_get_constraintdef(pgc.oid) as condef
          FROM information_schema.table_constraints tc
          JOIN pg_constraint pgc ON pgc.conname = tc.constraint_name
          JOIN pg_namespace nsp ON nsp.oid = pgc.connamespace
          WHERE tc.constraint_type = 'FOREIGN KEY'
          AND tc.table_schema = $1
          ORDER BY tc.table_name, tc.constraint_name;
        `,
          [schema],
        );

        if (fkResult.rows.length > 0) {
          write(`\n-- Foreign Keys for schema: ${schema}\n`);
          for (const fk of fkResult.rows) {
            write(
              `ALTER TABLE ${schema}.${fk.table_name} ADD CONSTRAINT "${fk.constraint_name}" ${fk.condef};\n`,
            );
          }
          write("\n");
        }
      }

      // Backup functions and procedures
      if (!dataOnly) {
        console.log(`‚öôÔ∏è  Backing up functions from schema: ${schema}...`);
        const functionsResult = await client.query(
          `
          SELECT
            p.proname as function_name,
            pg_get_functiondef(p.oid) as function_def
          FROM pg_proc p
          JOIN pg_namespace n ON p.pronamespace = n.oid
          WHERE n.nspname = $1
          AND p.prokind IN ('f', 'p')
          ORDER BY p.proname;
        `,
          [schema],
        );

        if (functionsResult.rows.length > 0) {
          write(`\n-- Functions and Procedures for schema: ${schema}\n`);
          for (const func of functionsResult.rows) {
            write(`${func.function_def};\n\n`);
            objectCounts.functions++;
          }
        }
      }

      // Backup triggers
      if (!dataOnly) {
        console.log(`‚ö° Backing up triggers from schema: ${schema}...`);
        const triggersResult = await client.query(
          `
          SELECT
            tgname as trigger_name,
            tgrelid::regclass as table_name,
            pg_get_triggerdef(oid) as trigger_def
          FROM pg_trigger
          WHERE tgisinternal = false
          AND tgrelid::regclass::text LIKE $1 || '.%'
          ORDER BY tgname;
        `,
          [schema],
        );

        if (triggersResult.rows.length > 0) {
          write(`\n-- Triggers for schema: ${schema}\n`);
          for (const trig of triggersResult.rows) {
            write(`${trig.trigger_def};\n`);
            objectCounts.triggers++;
          }
          write("\n");
        }
      }
    }

    // Write the final SQL content to file
    if (compress) {
      const compressed = zlib.gzipSync(sqlContent);
      fs.writeFileSync(filepath, compressed);
    } else {
      fs.writeFileSync(filepath, sqlContent);
    }

    const fileSize = fs.statSync(filepath).size;

    // Create metadata file
    const metadata = {
      backupName,
      timestamp: new Date().toISOString(),
      databaseName,
      postgresVersion,
      fileSize,
      compressed: compress,
      schemas,
      objectCounts,
    };

    fs.writeFileSync(metadataPath, JSON.stringify(metadata, null, 2));

    console.log(`\n‚úÖ Backup completed successfully!`);
    console.log(`üìÅ File saved to: ${filepath}`);
    console.log(`üìä Size: ${(fileSize / 1024).toFixed(2)} KB`);
    console.log(`üìã Metadata: ${metadataPath}`);
    console.log(`\nüìà Backup Statistics:`);
    console.log(`   - Tables: ${objectCounts.tables}`);
    console.log(`   - Views: ${objectCounts.views}`);
    console.log(`   - Sequences: ${objectCounts.sequences}`);
    console.log(`   - Functions: ${objectCounts.functions}`);
    console.log(`   - Triggers: ${objectCounts.triggers}`);
    console.log(`   - Enums: ${objectCounts.enums}`);
    console.log(`   - Extensions: ${objectCounts.extensions}`);

    return { filepath, metadata };
  } catch (error) {
    console.error("‚ùå Backup failed:", error.message);
    throw error;
  } finally {
    await client.end();
  }
}

// CLI usage
if (require.main === module) {
  const args = process.argv.slice(2);

  if (args.length < 2) {
    console.log(
      "Usage: node backup.js <connection_string> <backup_name> [--compress]",
    );
    console.log(
      'Example: node backup.js "postgresql://user:pass@host/db" my_backup --compress',
    );
    process.exit(1);
  }

  const [connectionString, backupName, ...flags] = args;
  const options = {
    compress: flags.includes("--compress"),
  };

  createBackup(connectionString, backupName, options)
    .then(() => process.exit(0))
    .catch(() => process.exit(1));
}

module.exports = { createBackup };
